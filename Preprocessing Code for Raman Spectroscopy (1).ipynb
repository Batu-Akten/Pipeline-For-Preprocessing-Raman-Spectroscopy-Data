{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee386f-c3d9-4a65-a81b-0c1fb5ee24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import normalize\n",
    "from alive_progress import alive_bar\n",
    "import os\n",
    "import glob\n",
    "from scipy.ndimage import median_filter\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece95a5-ed14-4d73-b8e0-6f58c623878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calibrate the x-axis of Raman Spectral Data(Create a polynomial that, when applied to pixel values, will change them to Raman Shift values)\n",
    "\n",
    "#Provide pixel values of identifiable peaks from a Raman Spectrum that was taken with your machine\n",
    "dataset1 = [116,\n",
    "184.5,\n",
    "251,\n",
    "376,\n",
    "480,\n",
    "785,\n",
    "974\n",
    "]\n",
    "\n",
    "#Provide Raman Shift Values of the same peaks that are of the same sample, taken from literature\n",
    "dataset2 = [365.676,\n",
    "484.588,\n",
    "601,\n",
    "812.223,\n",
    "974.5,\n",
    "1451.85,\n",
    "1728.9\n",
    " ]\n",
    "\n",
    "# Fit polynomial model\n",
    "mymodel = np.poly1d(np.polyfit(dataset1, dataset2, 3))\n",
    "\n",
    "\n",
    "# Directory containing Raman Spectrum Files\n",
    "directory = r'C:\\Users\\batua\\Downloads\\3rdGen_2024_newcystSamples_samePatients-20240710T165245Z-001\\3rdGen_2024_newcystSamples_samePatients\\20240709_Diluton_sample123\\Dilution_123_10mW\\1e4'\n",
    "# List to hold the processed numpy arrays\n",
    "all_data = []\n",
    "fitted_x = None\n",
    "\n",
    "# Process each CSV file in the directory\n",
    "for filepath in glob.glob(os.path.join(directory, '*')):\n",
    "    # Check if it's a file and not a directory\n",
    "    if os.path.isfile(filepath):\n",
    "        # Read the file into a pandas DataFrame\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "        \n",
    "        # Convert the DataFrame to a numpy array\n",
    "        data = df.values\n",
    "        \n",
    "        # Apply the polynomial model to the first file's x-axis\n",
    "        if fitted_x is None:\n",
    "            x = data[:, 0]\n",
    "            fitted_x = mymodel(x)\n",
    "        \n",
    "        # Replace the first column with the fitted x values\n",
    "        data[:, 0] = fitted_x\n",
    "        \n",
    "        # Append the processed data to the list\n",
    "        all_data.append(data[:, 1:])  # Exclude the first column (x-axis) for merging\n",
    "\n",
    "        # Debugging: Print shape of each array\n",
    "        print(f'Processed data shape from {filepath}: {data.shape}')\n",
    "\n",
    "# Ensure there is at least one array to concatenate\n",
    "if len(all_data) > 0:\n",
    "    # Stack columns (all files should have the same number of rows)\n",
    "    merged_data = np.column_stack(all_data)\n",
    "    \n",
    "    # Example: Print the shape of the merged data array\n",
    "    print(f'Merged data shape: {merged_data.shape}')\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"No data was processed. Please check the input directory and files.\")\n",
    "plt.plot(fitted_x, merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bef53-942f-4ff0-8887-a514b4a75676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the fitted values to a dataframe\n",
    "preproc_df = pd.DataFrame(data=merged_data, index=fitted_x, columns=np.arange(merged_data.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f7b49-fbe2-49c3-b841-696b1f1f07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preproc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6f56c-1648-4ca5-8d7a-7e7e98c7c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Pipeline\n",
    "\n",
    "#Necessary Functions\n",
    "def crop_spectrum(spectrum, lb, ub):\n",
    "    return spectrum[lb:ub+1]\n",
    "\n",
    "def despike_spectrum(spectrum, threshold=5):\n",
    "    filtered = median_filter(spectrum, size=3)\n",
    "    spikes = np.abs(spectrum - filtered) > threshold\n",
    "    spectrum[spikes] = filtered[spikes]\n",
    "    return spectrum\n",
    "\n",
    "def baseline_als(y, lam=1e5, p=0.01, niter=10):\n",
    "    L = len(y)\n",
    "    D = np.diff(np.eye(L), 2)\n",
    "    w = np.ones(L)\n",
    "    for i in range(niter):\n",
    "        W = np.diag(w)\n",
    "        Z = W + lam * D.dot(D.T)\n",
    "        z = np.linalg.solve(Z, w * y)\n",
    "        w = p * (y > z) + (1 - p) * (y < z)\n",
    "    \n",
    "    return z\n",
    "\n",
    "def baseline_correction(spectrum):\n",
    "    baseline = baseline_als(spectrum)\n",
    "    return spectrum - baseline\n",
    "\n",
    "def l2_normalize(spectrum):\n",
    "    norm = np.linalg.norm(spectrum)\n",
    "    if norm == 0:\n",
    "        return spectrum\n",
    "    return spectrum / norm\n",
    "\n",
    "#Preprocess Function\n",
    "def preprocess(data, lb, ub):\n",
    "    \"\"\"\n",
    "    data: the dataframe whose spectra need to be preprocessed\n",
    "    lb: the lower bound for the pixel numbers which need to be kept\n",
    "    ub: the upper bound for the pixel numbers which need to be kept\n",
    "\n",
    "    returns: the preprocessed dataframe\n",
    "    \"\"\"\n",
    "    raman_shifts = data.index[lb:ub+1]  # Raman shifts for the given range\n",
    "    num_pixels = ub - lb + 1  # number of pixels in the processed dataframe\n",
    "\n",
    "    spectra_array = np.zeros((len(data.columns), num_pixels))\n",
    "    length = len(data.columns)\n",
    "\n",
    "    for j in tqdm(range(length)):\n",
    "        spectrum = data.iloc[:, j].to_numpy()  # Process entire column as spectrum\n",
    "        cropped_spectrum = crop_spectrum(spectrum, lb, ub)\n",
    "        despiked_spectrum = despike_spectrum(cropped_spectrum)\n",
    "        denoised_spectrum = savgol_filter(despiked_spectrum, window_length=21, polyorder=5)\n",
    "        baseline_corrected_spectrum = baseline_correction(denoised_spectrum)\n",
    "        normalized_spectrum = l2_normalize(baseline_corrected_spectrum)\n",
    "        spectra_array[j, :] = normalized_spectrum\n",
    "\n",
    "    df = pd.DataFrame(spectra_array.T, index=raman_shifts, columns=data.columns)\n",
    "\n",
    "    print('Finished preprocess!')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8c7ac-6477-4e9d-a3c8-e297d296bd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
 
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
